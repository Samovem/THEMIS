{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN AURORA CLASSIFICATION.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "teM_2pbzSSuc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "oJP-_qpRK0Zc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Aurora Classification\n",
        "Aurora Images has been Sliced and cropped, and then manually labeled to be able to classify those images using a CNN"
      ]
    },
    {
      "metadata": {
        "id": "QNnWXTzLnPTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c47c7682-c73c-427d-9dd5-42996aa6fcfa"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m  HTTP error 403 while getting http://download.pytorch.org/whl/cu80/torch-0.4.0.post4-cp36-cp36m-linux_x86_64.whl\u001b[0m\n",
            "\u001b[31m  Could not install requirement torch==0.4.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.4.0.post4-cp36-cp36m-linux_x86_64.whl because of error 403 Client Error: Forbidden for url: http://download.pytorch.org/whl/cu80/torch-0.4.0.post4-cp36-cp36m-linux_x86_64.whl\u001b[0m\n",
            "\u001b[31mCould not install requirement torch==0.4.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.4.0.post4-cp36-cp36m-linux_x86_64.whl because of HTTP error 403 Client Error: Forbidden for url: http://download.pytorch.org/whl/cu80/torch-0.4.0.post4-cp36-cp36m-linux_x86_64.whl for URL http://download.pytorch.org/whl/cu80/torch-0.4.0.post4-cp36-cp36m-linux_x86_64.whl\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yi0bznJynnzH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pathlib\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6d7bZuR1n3qA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a01b7591-3276-4aa2-a5e8-f7377b25d16a"
      },
      "cell_type": "code",
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "print(cuda_available)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BcAL1_xCpKL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ca90db3-6084-49ca-93b5-f610d48fdad4"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nHeidelberg/THEMIS"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'THEMIS' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0AgN5a_g5LFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "19295d2c-8870-42a0-dd8e-7881d4535183"
      },
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir -I pillow"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 66.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0WKW73GAN-Qj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# workaround for PIL problem...\n",
        "from PIL import Image\n",
        "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "  for extension in extensions: register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_9a6_ZImIEp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 6\n",
        "num_classes = 2\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_workers = 3\n",
        "lr = 0.0001\n",
        "momentum = 0.0001\n",
        "train_path = './THEMIS/data/train'\n",
        "\n",
        "# transforms to apply to the data\n",
        "train_loader = data.DataLoader(\n",
        "    datasets.ImageFolder(train_path,\n",
        "                         transforms.Compose([\n",
        "                             transforms.RandomResizedCrop(32),\n",
        "                             transforms.RandomHorizontalFlip(),\n",
        "                             torchvision.transforms.Grayscale(),\n",
        "                             transforms.ToTensor(),\n",
        "                         ])),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CerKBnKhyxqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.drop_out = nn.Dropout()\n",
        "        self.fc1 = nn.Linear(4096, 1000)\n",
        "        self.fc2 = nn.Linear(1000, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "model = ConvNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kwVcWYGvHwBv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Run the forward pass\n",
        "        outputs = model(Variable(images))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backprop and perform Adam optimisation\n",
        "        loss = criterion(outputs, Variable(labels))\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HNsV4xcUPqHK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def single_error(model, images):\n",
        "     return torch.argmax(F.softmax(model(Variable(images)), dim=1),dim=1)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pxt2ADZzLTv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffc916ea-fa10-4147-9f52-4ba4ade4037a"
      },
      "cell_type": "code",
      "source": [
        "for idx, (images, labels) in enumerate(train_loader):\n",
        "    if idx == 0:\n",
        "        _, predicted = torch.max(F.softmax(model(Variable(images)), dim=1), 1)\n",
        "        count = 0\n",
        "        for pred, label in zip(predicted,labels):\n",
        "            if(int(pred) == int(label)):\n",
        "                count += 1\n",
        "        print('The accuracy on the training set:',count*100/64)\n",
        "    else:\n",
        "        break"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy on the training set: 70.3125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Df9U7PReU_DY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
